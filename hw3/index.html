<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184/284A Rasterizer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<body>

<h1 align="middle">CS 184/284A: Computer Graphics and Imaging, Spring 2024</h1>
<h1 align="middle">Homework 3-1</h1>
<h2 align="middle">Sylvia Chen, Artem Shumay</h2>
<div align="middle"> 
	<p><a href="https://cal-cs184-student.github.io/hw-webpages-sp24-sylviacx/hw3/index.html">https://cal-cs184-student.github.io/hw-webpages-sp24-sylviacx/hw3/index.html</a>
	</p>
</div>

<br><br>

<div>

<h2 align="middle">Overview</h2>
<p>
	Overall, we implemented parts of ray tracing, focusing a lot on rays and intersections between rays and scene objects.
	Through these exercises, we gained a lot of experience on generating rays, checking intersections, building BVH trees, global illumination, and several techniques of increasing the efficiency of these algorithms.
	This project was hard to debug, since there were so many moving parts and it was hard to tell what the problem was from looking at the output, but it was also really interesting to see how the lighting accuracy increased with each step!
	
</p>

<h3 align="middle">Part 1: Ray Generation and Scene Intersection</h3>

<h4 align="left">Camera::generate_ray</h4>
<p> 
	This function takes in normalized image coordinates (x, y) and returns a Ray struct in world space.  
	Our camera space is defined by corners (-tan(0.5 * hFov), -tan(0.5  * vFov),  -1) and (tan(0.5 * hFov), tan(0.5  * vFov),  -1), while image space is defined by corners (0, 0) and (1, 1).
	Thus, we can use simple arithmetic to translate between image and camera coordinates. We set the z coordinate to -1 always. For example, given image coordinate x, we can calculate the camera space coordinate using the formula:

	<div style="text-align: center;">
		<span style="font-size: 20px;"><b>camera_space_x = -tan(0.5 * hFov) + x * 2 * tan(0.5, hFov)</b></span>
	</div>

	Then, once we have successfully translated from image to camera space, we multiply the camera space coordinates by the camera-to-world rotation matrix <code>c2w</code>. 
	Now we can generate a Ray from the original ray's origin <code>pos</code> and world space coordinates of x, y, z.
	Finally, we set the <code>min_t</code> and <code>max_t</code> of the new ray to <code>nClip</code> and <code>fClip</code> respectively, as said in the spec.
</p>

<h4 align="left">Triangle Intersection Algorithm</h4>
<p>
	To check if a ray intersects a triangle, we use the Moller Trumbore Algorithm as taught in lecture. 
	We calculate variables E1, E2, S, S1, and S2 according to the algorithm and use arithmetic to get t, b1, and b2. 
	If the values for t, b1, and b2 are not valid, we return False, since that means the ray does not intersect with the triangle.
	Otherwise, we update the input ray's max t value with t if t < r.max_t.
	If <code>t < r.max_t</code>, then we have to update r.max_t since this means that the intersection point we found for this triangle is closer than the max t for this ray.
	We need to prevent future intersections at t` where t` > t from updating the Intersection data, since those intersections will be farther than t and we are only interested in returning the closest intersection.
	Finally, we update the Intersection data according to the spec. 
	For <code>Triangle::has_intersection</code>, we simply call <code>Triangle::intersect</code> without updating the Intersection data.

	<div align="middle">
		<table style="width:100%">
		  <tr align="center">
			<td>
			  <img src="https://media.discordapp.net/attachments/1206892000390156318/1216854931982778398/image.png?ex=6601e777&is=65ef7277&hm=fdd52494aa2c7c0fd4a56af4261b6b6da662c51eb936f97736441695650a9ae1&=&format=webp&quality=lossless&width=822&height=563" align="middle" width="800px"/>
			  <figcaption align="middle">Moller Trumbore Algorithm</figcaption>
			</td>
		  </tr>
		</table>
	</div> 
</p>

<div align="middle">
	<table style="width:100%">
	  <tr align="center">
		<td>
		  <img src="https://media.discordapp.net/attachments/1206892000390156318/1216853186690941028/CBempty.png?ex=6601e5d7&is=65ef70d7&hm=628a1653cdce8354e99cf163d5a7707f7689f46d6dfb72ee44f14124b34fb369&=&format=webp&quality=lossless&width=883&height=662" align="middle" width="400px"/>
		  <figcaption align="middle">CBempty.dae</figcaption>
		</td>
		<td>
			<img src="https://media.discordapp.net/attachments/1206892000390156318/1216853422628929628/CBspheres.png?ex=6601e60f&is=65ef710f&hm=d97cbcfdd82e612cb99d68f097debaefd45d234fc7ed7747570fa653a9896e77&=&format=webp&quality=lossless&width=883&height=662" align="middle" width="400px"/>
			<figcaption align="middle">CBspheres_lambertian.dae</figcaption>
		</td>
	  </tr>
	</table>
</div>

<div align="middle">
	<table style="width:100%">
	  <tr align="center">
		<td>
			<img src="https://media.discordapp.net/attachments/1206892000390156318/1216903326105473084/cow.png?ex=66021489&is=65ef9f89&hm=f87d3d05585dd21fc151ebbe706666a6a66ea9e986b2b6d189dd4471dae63d7c&=&format=webp&quality=lossless&width=883&height=662" align="middle" width="400px"/>
			<figcaption align="middle">CBgems.dae</figcaption>
		</td>
		<td>
			<img src="https://media.discordapp.net/attachments/1206892000390156318/1216853871465599006/bunny.png?ex=6601e67b&is=65ef717b&hm=ad96285c3633eee6a52bc3379f7b740d62f528285ddf7d4e1c16adb2602a05b1&=&format=webp&quality=lossless&width=883&height=662" align="middle" width="400px"/>
			<figcaption align="middle">cow.dae</figcaption>
		</td>
	  </tr>
	</table>
</div>

<h3 align="middle">Part 2: Bounding Volume Hierarchy</h3>

<h4 align="left">BVHAccel::construct_bvh</h4>
<p>
	We chose to split our BVH tree such that the left and right nodes would have an equal number of primitives in them by splitting on the median left bound with respect to the axis with the largest extent.
	First, we created a new BVHNode from a bbox with all the primitives from start to end. 
	If the number of primitives inside the bbox was less than <code>max_leaf_size</code>, then we would just need to set the new node's start and end, without recursing.
	Otherwise, we sorted start to end in order of increasising min.{axis} values, where the axis is the axis with the longest extent. 
	Finally, we recursed by setting the new node's left and right child to recursive calls to <code>construct_bvh</code>. 
	<code>node->l</code> becomes a BVH tree from start to the median primitive.
	<code>node->r</code> becomes a BVH tree from the median primitive to end.
</p>

<div align="middle">
	<table style="width:100%">
	  <tr align="center">
		<td>
		  <img src="https://media.discordapp.net/attachments/1206892044363239485/1216858247756124441/cow.png?ex=6601ea8e&is=65ef758e&hm=450803d1a794545d638fdc51e8b2e663eaaf41525a7042a573fe765dcf28b76a&=&format=webp&quality=lossless&width=883&height=662" align="middle" width="400px"/>
		  <figcaption align="middle">maxplanck.dae</figcaption>
		</td>
		<td>
			<img src="https://media.discordapp.net/attachments/1206892044363239485/1216858392635899994/cow.png?ex=6601eab0&is=65ef75b0&hm=02c8baa4bfeb99e171968b908d29c736ca8e4aaf55ae8ba990422b8d2babf113&=&format=webp&quality=lossless&width=883&height=662" align="middle" width="400px"/>
			<figcaption align="middle">CBlucy.dae</figcaption>
		</td>
	  </tr>
	</table>
</div>

<div align="middle">
	<table style="width:100%">
	  <tr align="center">
		<td>
			<img src="https://media.discordapp.net/attachments/1206892044363239485/1216859318691954859/cow.png?ex=6601eb8d&is=65ef768d&hm=ed1c0da05e50075377e7ee2d68cf5a61a2d077646d7b0d5addd27b1e2f9265a3&=&format=webp&quality=lossless&width=883&height=662" align="middle" width="400px"/>
			<figcaption align="middle">CBdragon.dae</figcaption>
		</td>
		<td>
			<img src="https://media.discordapp.net/attachments/1206892044363239485/1216903784752615505/cow.png?ex=660214f7&is=65ef9ff7&hm=feddc3aa42cbaf1e4c51eea781e7a7abecba8f3528e51e5810caa0ef86c589c0&=&format=webp&quality=lossless&width=883&height=662" align="middle" width="400px"/>
			<figcaption align="middle">CBdragon.dae</figcaption>
		</td>
	  </tr>
	</table>
</div>

<p>
	We tried rendering 3 moderately complex geometries with and without BVH acceleration, and found that the difference was drastic. 
	CBcoil.dae took about 40 seconds to render without BVH acceleration, but only took about 0.05 seconds to render with BVH acceleration.
	CBgems.dae took about 1.3 seconds to render without BVH acceleration, but only took 0.05 seconds to render with BVH acceleration.
	teapot.dae took about 12 seconds to render without BVH acceleration, but only took 0.09 seconds to render with BVH acceleration.
	From these observations, it is clear that BVH acceleration greatly improves performance of rendering.
</p>

<div align="middle">
	<table style="width:100%">
	  <tr align="center">
		<td>
		  <img src="https://media.discordapp.net/attachments/1206892044363239485/1216861114223169677/cow.png?ex=6601ed39&is=65ef7839&hm=126d8b9254031875720ebb4dae4510e9c7945f4e819c27ab25070619d650780b&=&format=webp&quality=lossless&width=883&height=662" align="middle" width="400px"/>
		  <figcaption align="middle">CBcoil.dae without BVH: 39.9075s</figcaption>
		</td>
		<td>
			<img src="https://media.discordapp.net/attachments/1206892044363239485/1216862293699203102/cow.png?ex=6601ee53&is=65ef7953&hm=4f85434b23c635935bfa8293bd8f1e4eb4debf2c4d2ab0dfc079e77aeb71bd45&=&format=webp&quality=lossless&width=883&height=662" align="middle" width="400px"/>
			<figcaption align="middle">CBcoil.dae with BVH: 0.0487s</figcaption>
		</td>
	  </tr>
	</table>
</div>
<div align="middle">
	<table style="width:100%">
	  <tr align="center">
		<td>
		  <img src="https://media.discordapp.net/attachments/1206892044363239485/1216861455073149058/cow.png?ex=6601ed8b&is=65ef788b&hm=eb1c4cb5e9367c6138b8b9a01c9c98889ba2bf33ed00cffc27f42507e85fa44b&=&format=webp&quality=lossless&width=883&height=662" align="middle" width="400px"/>
		  <figcaption align="middle">CBgems.dae without BVH: 1.3114s</figcaption>
		</td>
		<td>
			<img src="https://media.discordapp.net/attachments/1206892044363239485/1216862187570860194/cow.png?ex=6601ee39&is=65ef7939&hm=9e248c5c594be875575250455e145307e893e847bdce98f59028ac986817dfbb&=&format=webp&quality=lossless&width=883&height=662" align="middle" width="400px"/>
			<figcaption align="middle">CBgems.dae with BVH: 0.0560s</figcaption>
		</td>
	  </tr>
	</table>
</div>
<div align="middle">
	<table style="width: 100%">
	  <tr align="center">
		<td>
		  <img src="https://media.discordapp.net/attachments/1206892044363239485/1216861642424320061/cow.png?ex=6601edb7&is=65ef78b7&hm=496345295780035977ff889c0bca64dbbb5aec46e0b225707cc512a0163daab7&=&format=webp&quality=lossless&width=883&height=662" align="middle" width="400px"/>
		  <figcaption align="middle">teapot.dae without BVH: 12.1659s</figcaption>
		</td>
		<td>
			<img src="https://media.discordapp.net/attachments/1206892044363239485/1216862046071820419/cow.png?ex=6601ee17&is=65ef7917&hm=8d73e6e7783b0159192aa06fcade6240c4160b7c10ec034ff7a40cf573d75798&=&format=webp&quality=lossless&width=883&height=662" align="middle" width="400px"/>
			<figcaption align="middle">teapot.dae with BVH: 0.0930s</figcaption>
		</td>
	  </tr>
	</table>
</div>
	
<h3 align="middle">Part 3: Direct Illumination</h3>
<p> Walk through both implementations of the direct lighting function.
	Show some images rendered with both implementations of the direct lighting function.
	Focus on one particular scene with at least one area light and compare the noise levels in soft shadows when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, not uniform hemisphere sampling.
	Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis.</p>

<h4 align="left">PathTracer::estimate_direct_lighting_hemisphere</h4>
<p>
	The first implementation of direct lighting uses uniform hemisphere sampling. 
	Conceptually, this technique shoots rays from a hit point in uniformly random directions sampled from a hemisphere about the point, checking whether or not the ray intersects with objects in the scene.
	Depending on the intersection, we can then use the Monte Carlo estimation of the reflection equation to determine how much light is reflected to the camera from the hit point.
	In further detail, this technique samples <code>scene->lights.size() * ns_area_light</code> directional vectors (wj) from the hemisphere at random.
	We then convert these directional vectors into world space and use them to create rays originating from hit_p.
	We set the rays' min_t to EPS_F to account for small precision errors, as instructed by the spec.
	If a new ray intersects with something in our BVH tree, we add to our sum using the Monte Carlo estimation of the reflectance equation.

	<div align="middle">
		<table style="width: 100%">
		  <tr align="center">
			<td>
			  <img src="https://media.discordapp.net/attachments/1206892064411750410/1216912819040161822/image.png?ex=66021d61&is=65efa861&hm=174d1f9727875d38d605b38f81664afdef7e521735cdbdb82e2feafff041d685&=&format=webp&quality=lossless&width=608&height=138" align="middle" width="400px"/>
			</td>
		  </tr>
		</table>
	</div>

	In our implementation, isect.bsdf->f is our fr function, Li is the bsdf emission of the intersectio point, cos(theta) is the z coordinate of object space wj, and pdf is 1 / 2 * pi.
	Finally, once we have finished creating rays, we average the sum by dividing by number of samples.
</p>

<h4 align="left">PathTracer::estimate_direct_lighting_importance</h4>
<p>
	The second implementation of direct lighting uses importance sampling.
	Conceptually, this technique aims to improve the noisiness of the previous method by sampling rays originating from a hit point directly to each light source in the scene.
	Instead of sampling a number of uniformly random rays about a hemisphere regardless of the number of light sources, in importance sampling we sample ns_area_light directional vectors (wi) for each light source.
	However, if the light source is a point light source, we only need to sample once. 
	If the z component of object space wi is less than 0, then that means the light source is behind our hit point and we don't need to continue. 
	Otherwise, we generate a ray from world space wi and originating at the hit point, but we also set its max_t to dst - ESP_F since we only care about intersections before the light source.
	In this implementation, an intersection means there is something obstructing the light source from the hit point, so we are conditioned on NOT intersecting the BVH tree. 
	For each light, we keep a running sum of the reflection from this light, calculated using the same Monte Carlo estimation of the reflectance equation from the previous implementation.
	In our implementation, isect.bsdf->f is our fr function, Li is radiance returned by scene->lights[i]->sample_L, cos(theta) is the z coordinate of object space wi, and pdf is determined by scene->lights[i]->sample_L.
	Once we finish iterating over all the samples for a light i, we add the average light reflection of light i into a running total sum.
	Once we finish iterating over all the lights, we return the average of the running total sum.
</p>

<div align="middle">
	<table style="width: 100%">
	  <tr align="center">
		<td>
		  <img src="https://media.discordapp.net/attachments/1206892064411750410/1216925148905476146/CBbunny_H_64_32.png?ex=660228dc&is=65efb3dc&hm=ccb9e652668d0d44d478291baf273b6cba98f39cc0a107dd321bebe023bb7cdd&=&format=webp&quality=lossless&width=600&height=450" align="middle" width="400px"/>
		  <figcaption align="middle">CBbunny.dae with uniform hemipshere sampling</figcaption>
		</td>
		<td>
			<img src="https://media.discordapp.net/attachments/1206892064411750410/1217180224026841119/bunny_64_32.png?ex=6603166b&is=65f0a16b&hm=2c8c435754d552c80b257abb17b9aa10b6b77366341bf96d8d31166b6ded7b70&=&format=webp&quality=lossless&width=600&height=450" align="middle" width="400px"/>
			<figcaption align="middle">CBbunny.dae with importance sampling</figcaption>
		</td>
	  </tr>
	</table>
</div>
<div align="middle">
	<table style="width: 100%">
	  <tr align="center">
		<td>
		  <img src="https://media.discordapp.net/attachments/1206892064411750410/1217179476635553862/CBbunny_H_64_32.png?ex=660315b9&is=65f0a0b9&hm=44be9dbb2823ccfbbc463c36aa41a925b074034f42aff9fb686f9ce24b6358ff&=&format=webp&quality=lossless&width=600&height=450" align="middle" width="400px"/>
		  <figcaption align="middle">CBspheres_lambertian.dae with uniform hemipshere sampling</figcaption>
		</td>
		<td>
			<img src="https://media.discordapp.net/attachments/1206892064411750410/1217180506571931720/bunny_64_32.png?ex=660316ae&is=65f0a1ae&hm=7fff5fa3509d821a5167af651653ad61772ef1e62dddbd1c213f914523bc16ab&=&format=webp&quality=lossless&width=600&height=450" align="middle" width="400px"/>
			<figcaption align="middle">CBspheres_lambertian.dae with importance sampling</figcaption>
		</td>
	  </tr>
	</table>
</div>

<p>
	With a lower number of rays, we can see that noise in the soft shadows are higher in comparison to shadows formed from a higher number of rays.
</p>

<div align="middle">
	<table style="width: 100%">
	  <tr align="center">
		<td>
		  <img src="https://media.discordapp.net/attachments/1206892064411750410/1217182479807414312/bunny_64_32.png?ex=66031885&is=65f0a385&hm=7392f606ba2a95a4a0c91b9fd869a26ba43958b52e80d7eb6a76d960541c28a7&=&format=webp&quality=lossless&width=600&height=450" align="middle" width="400px"/>
		  <figcaption align="middle">Importance sampling: 1 sample per pixel, 1 light ray</figcaption>
		</td>
		<td>
			<img src="https://media.discordapp.net/attachments/1206892064411750410/1217182602113323028/bunny_64_32.png?ex=660318a2&is=65f0a3a2&hm=b771e359a25a00ec2bf1887a1c7b7e47073108bd25f25bf416e27c7261472e58&=&format=webp&quality=lossless&width=600&height=450" align="middle" width="400px"/>
			<figcaption align="middle">Importance sampling: 1 sample per pixel, 4 light rays</figcaption>
		</td>
	  </tr>
	</table>
</div>
<div align="middle">
	<table style="width: 100%">
	  <tr align="center">
		<td>
		  <img src="https://media.discordapp.net/attachments/1206892064411750410/1217182712415256646/bunny_64_32.png?ex=660318bc&is=65f0a3bc&hm=b59737a58db1a42007b34e4a9e04655375ce7680a55e6c873fe39d8aa288d4ea&=&format=webp&quality=lossless&width=600&height=450" align="middle" width="400px"/>
		  <figcaption align="middle">Importance sampling: 1 sample per pixel, 16 light rays</figcaption>
		</td>
		<td>
			<img src="https://media.discordapp.net/attachments/1206892064411750410/1217182817822441612/bunny_64_32.png?ex=660318d5&is=65f0a3d5&hm=9b35571c1654579c508d81c7f5d4fc0cff0a8a774ee9643568883c70fc9d8eb8&=&format=webp&quality=lossless&width=600&height=450" align="middle" width="400px"/>
			<figcaption align="middle">Importance sampling: 1 sample per pixel, 64 light rays</figcaption>
		</td>
	  </tr>
	</table>
</div>

<p>
	From this part, we have observed that uniform hemisphere sampling results in overall noisier renders. 
	While the shadows and highlights are still soft, visually it looks like there is a grain filter over the entire image.
	Furthermore, the images produced by uniform hemisphere sampling have a blur around the light source in the ceiling.
	In comparison, the images generated from importance sampling have smooth, grainless walls and the light source is in a cleanly cut rectangle.
	However, with a lower number of rays, importance sampling also produces grainy images.
</p>

<h3 align="middle">Part 4: Global Illumination (20 Points)</h3>
<!-- Walk through your implementation of the indirect lighting function.
Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
You will probably want to use the instructional machines for the above renders in order to not burn up your own computer for hours. -->

<p>
    For our indirect lighting function, we first check Russian Roulette chance or if the ray is at it's max depth. If any of those conditions are true we finish. 
	Otherwise we estimate one bounce radiance of the current ray, cast another ray from hit_point, and using the recursive radiance estimation from the new ray sum it to current ray (using formula for direct lighting).  
</p>
<br>

<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="https://cdn.discordapp.com/attachments/1206889873798332446/1217356365391990794/spheres_global.png?ex=6603ba76&is=65f14576&hm=5048f62d01974b51bd19c45b97c78a3d1ea01e475665604fe2308cabf85900db&" align="middle" width="400px"/>
        <figcaption>Spheres.dae rendered with global illumination</figcaption>
      </td>
      <td>
        <img src="https://cdn.discordapp.com/attachments/1206889873798332446/1217361027273068574/coil.png?ex=6603bece&is=65f149ce&hm=d28d9b7eeec946a01f806d397c1ad1ed3e0333d090395599bdae49e9179d4727&" align="middle" width="400px"/>
        <figcaption>Dragon.dae rendered with global illumination</figcaption>
      </td>
    </tr>
  </table>
</div>

<p>
    Below are 2 images of dragon.dae, one with only direct illumation and one with only indirect illumination.
	For only direct we only see parts of the dragon directly hitting the light. For the indirect we see how much light is gotten from the second bounce of light.
	Notice how parts which were darker on first image are lighter on second one, this is because some parts may not get direct light, but can get light reflected off other surfaces.
	This is how indirect lighting lights up parts of the mesh in shadow.
</p>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="https://cdn.discordapp.com/attachments/1206889873798332446/1217374552611491850/dragon_direct.png?ex=6603cb67&is=65f15667&hm=cdd67894d9681fd290651aa4dfd2b5eff7992fa2beeadd4963fe55d252f9c142&" align="middle" width="400px"/>
        <figcaption>Only direct illumination (dragon.dae)</figcaption>
      </td>
      <td>
        <img src="https://cdn.discordapp.com/attachments/1206889873798332446/1217370876656222298/coil.png?ex=6603c7fa&is=65f152fa&hm=f61d68aeecc3f5656ae166a34d888208a1811116751239c4022c475aebf650ce&" align="middle" width="400px"/>
        <figcaption>Only indirect illumination (dragon.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<p>
	Below are renders of CBunny.dae with max_ray_depth set to 0, 1, 2, 3, 4, and 5 (the -m flag), and isAccumBounces=false.
    On each image we see light from mth bounce of light. First one is direct. Second one and further is light from other surfaces reflecting light.
	Bounces are blended to the original image, so we can see how their significance decreases with further bounces. However, without them parts of the object obscured from the light source would be completely black.
</p>
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="https://cdn.discordapp.com/attachments/1217346917214716044/1217347067958005821/bunny_no_accum0.png?ex=6603b1ce&is=65f13cce&hm=639a69013ba80c4b530d50f32a1e4a5be8b44aa1b388242e7a7c16a4a3edff86&" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 0 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="https://cdn.discordapp.com/attachments/1217346917214716044/1217347079970619413/bunny_no_accum1.png?ex=6603b1d1&is=65f13cd1&hm=a4d304bccec674be2e253d53a9b2ea46fae6e06908a2d3da00599d4c54ca5646&" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 1 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="https://cdn.discordapp.com/attachments/1217346917214716044/1217347538550784000/bunny_no_accum2.png?ex=6603b23e&is=65f13d3e&hm=396c8978ab9380369a6393eedf272a0879e358bb0134121ac586265729c226da&	" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 2 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="https://cdn.discordapp.com/attachments/1217346917214716044/1217347546570297344/bunny_no_accum3.png?ex=6603b240&is=65f13d40&hm=21bd3ce18e6ff85366d38e7a3da9f243050b92dd9ce029f53f3d21bdeb002ad5&" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 3 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="https://cdn.discordapp.com/attachments/1217346917214716044/1217347556229517362/bunny_no_accum4.png?ex=6603b242&is=65f13d42&hm=9b40021d978888413ccc76ab8ad6986ac0d764503c5457cdb2b249a356a45db0&" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 4 (CBbunny.dae)</figcaption>
      </td>
		<td>
		<img src="https://cdn.discordapp.com/attachments/1217346917214716044/1217352007375917176/bunny_no_accum5.png?ex=6603b667&is=65f14167&hm=9d0721eec79d53e2471be996c93a5225b943996a70055d4d3da1b823bf199dde&" align="middle" width="400px"/>
		<figcaption>max_ray_depth = 5 (CBbunny.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<p>
	Below are renders of CBbunny.dae with max_ray_depth set to 0, 1, 2, 3, 4, and 5 (the -m flag), and isAccumBounces=true.
    Here we see bunny with accumulated ray bounces. We can see a very visible change between m=1 and m=2, but less between next ones. This is because each consecutive light bounce contributes less to the overall image.	
</p>
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="https://cdn.discordapp.com/attachments/1217346917214716044/1217346991114424400/bunny_accum0.png?ex=6603b1bb&is=65f13cbb&hm=cdd6b616cd893f288e6c698d87639f12eb7e953c6485097f6119f062829c5478&" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 0 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="https://cdn.discordapp.com/attachments/1217346917214716044/1217347001625215027/bunny_accum1.png?ex=6603b1be&is=65f13cbe&hm=cc20225fbf91e95acb99b3e4f5ec2d7caa4963a420ded4094f9c339d6f4758ae&" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 1 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="https://cdn.discordapp.com/attachments/1217346917214716044/1217347014811975731/bunny_accum2.png?ex=6603b1c1&is=65f13cc1&hm=612977dbb7e4835af203b9388b4528a4912010ba3a14dc016056394193265431&" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 2 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="https://cdn.discordapp.com/attachments/1217346917214716044/1217347029664268288/bunny_accum3.png?ex=6603b1c5&is=65f13cc5&hm=c60b0bbde5da6f17b4a543e40739a0cdf2a2b1c0c146de520aa07515b6b349e8&" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 3 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="https://cdn.discordapp.com/attachments/1217346917214716044/1217347041441611886/bunny_accum4.png?ex=6603b1c7&is=65f13cc7&hm=8820ad416a4163eb2ad7fd0e24c0b818c86fe34ee0ef78b2b5eb675f33842084&" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 4 (CBbunny.dae)</figcaption>
      </td>
		<td>
		<img src="https://cdn.discordapp.com/attachments/1217346917214716044/1217347054733627402/bunny_accum5.png?ex=6603b1cb&is=65f13ccb&hm=16e1d22dac88c54b8fee2580e1a9cdec78dd5aa4f34e005979a47d3d8ac373d3&" align="middle" width="400px"/>
		<figcaption>max_ray_depth = 5 (CBbunny.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<p>
	Below are renders of CBbunny.dae with max_ray_depth set to 0, 1, 2, 3, and 100, using Russian Roulette with probability of 0.35.
    Because we are using Russian Roulette rendering with factor 0.35 we will average about 3-4 bounces. But even without it bounces after 3-4 have minimal effect on the image, as seen in the previous example.
	Because of all this the image at m=100 does not look too different.
	We can conclude, that effect from bounces on this image after 4 bounces can be approximated by 0. 
</p>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="https://cdn.discordapp.com/attachments/1206889873798332446/1217340389724524584/bunny_rr0.png?ex=6603ab96&is=65f13696&hm=a92281bb1aa0926d8d9ba783230cb8f7ee272080fcec45c4a6d88f686e1df57b&" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 0 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="https://cdn.discordapp.com/attachments/1206889873798332446/1217342986556411944/bunny_rr1.png?ex=6603ae01&is=65f13901&hm=363b76d66e3bf1e607537e8f01baefd759d2e0c02ea7bbe2e46d7f5b625ae1a9&" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 1 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="https://cdn.discordapp.com/attachments/1206889873798332446/1217345626732363856/bunny_rr2.png?ex=6603b076&is=65f13b76&hm=e62abe6cca2e35266971195422f00d909d0a72f9802d85527cf00d117322987d&" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 2 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="https://cdn.discordapp.com/attachments/1206889873798332446/1217348645418958938/bunny_rr3.png?ex=6603b346&is=65f13e46&hm=9b0a9e6df26d667054ddcd0a17c56b751f23ab9fa4e7d5df09755ca4e7ed5938&" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 3 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="https://cdn.discordapp.com/attachments/1206889873798332446/1217349953840484422/bunny_rr4.png?ex=6603b47e&is=65f13f7e&hm=ee2c60fe2934a12fb0121795b7cf2edc5684af3dd26ffb69c462a5313a30685b&" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 100 (CBbunny.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>


<h3>
  Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
</h3>
<p>
	Below are renders of CBbunny.dae with sample-per-pixel rates 1, 2, 4, 8, 16, 64, and 1024 and using 4 light rays.
    We are sending rays in random directions.
	Because of this sometimes the ray might instantly hit light source or go out of the box and not hit anything, this is seen on 1 sample per pixel very well.
	To combat such effect, we increase number of samples, this averages the pixel to it's true color.
</p>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="https://cdn.discordapp.com/attachments/1206889873798332446/1217355677262020609/bunny_samples1.png?ex=6603b9d2&is=65f144d2&hm=e4c8e6ac9f80f3a73e1081e82f254f05dd92b7ca546b4cd0f0f653f5d248e732&" align="middle" width="400px"/>
        <figcaption>1 sample per pixel (example1.dae)</figcaption>
      </td>
      <td>
        <img src="https://cdn.discordapp.com/attachments/1206889873798332446/1217355754684809246/bunny_samples2.png?ex=6603b9e5&is=65f144e5&hm=15fb0e20170c864fd53a58279262afcaf1cd777fb9d9d904c9524e7c26e4ab8d&" align="middle" width="400px"/>
        <figcaption>2 samples per pixel (example1.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="https://cdn.discordapp.com/attachments/1206889873798332446/1217355789077975070/bunny_samples4.png?ex=6603b9ed&is=65f144ed&hm=42e468e924931e7e1676a0a2c411e87946022db6aa720c9856810732a906dc64&" align="middle" width="400px"/>
        <figcaption>4 samples per pixel (example1.dae)</figcaption>
      </td>
      <td>
        <img src="https://cdn.discordapp.com/attachments/1206889873798332446/1217355821420384369/bunny_samples8.png?ex=6603b9f5&is=65f144f5&hm=7a308de6f0da9c5c2ff3dc35d84cd383d5371fb614744ad647b3dd23824bd4b2&" align="middle" width="400px"/>
        <figcaption>8 samples per pixel (example1.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="https://cdn.discordapp.com/attachments/1206889873798332446/1217355860813025364/bunny_samples16.png?ex=6603b9fe&is=65f144fe&hm=2581e0d8d86b855f9327c63587de594b8adaa3c6ec64145c58863ed915c8b21f&" align="middle" width="400px"/>
        <figcaption>16 samples per pixel (example1.dae)</figcaption>
      </td>
      <td>
        <img src="https://cdn.discordapp.com/attachments/1206889873798332446/1217355894023782480/bunny_samples64.png?ex=6603ba06&is=65f14506&hm=d5abc61f57a29831ef0a03870dd0f6ec310b2fe3b7c3eb5327b4002bdfbb034b&" align="middle" width="400px"/>
        <figcaption>64 samples per pixel (example1.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="https://cdn.discordapp.com/attachments/1206889873798332446/1217361739805622292/bunny_samples1024.png?ex=6603bf78&is=65f14a78&hm=1347cdcd334c8ce605277105dff71e40fa9448e567abe328f5fc940361f216b9&" align="middle" width="400px"/>
        <figcaption>1024 samples per pixel (example1.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<h3 align="middle">Part 5: Adaptive Sampling</h3>
<p>
	Conceptually, adaptive sampling is an algorithm that uses higher sample rates on difficult to render parts of the image, while using lower sample rates on the easier parts.
	This allows us to remove noise without uniformly raising the sampling rate, since some pixels won't need a higher sampling rate to reduce noise. 
	We implemented the same algorithm presented in the spec, which starts keeping track of 2 variables, s1 and s2.
	s1 is the sum of illuminances for all samples for this pixel, and s2 is the sum of squared illumances for all samples for this pixel. 
	Every time we sample a factor of <code>samplesPerBatch</code> number of samples, we check if <code>I <= maxTolerance * μ</code>, where:

	<div style="text-align: center;">
		<span style="font-size: 20px;"><b>n = number of samples so far</b></span>
	</div>

	<div style="text-align: center;">
		<span style="font-size: 20px;"><b>μ = s1 / n</b></span>
	</div>

	<div style="text-align: center;">
		<span style="font-size: 20px;"><b>σ = (1 / (n - 1)) * (s2 - s1<sup>2</sup>/n)</b></span>
	</div>

	<div style="text-align: center;">
		<span style="font-size: 20px;"><b>I = 1.96 * (σ / √n)</b></span>
	</div>

	If the condition is true, we break out of the sampling loop and record whatever number of samples we ended with. 
	We also break out of the loop once we reach <code>num_samples</code> number of pixels.
	This way, for each pixel, we sample at most <code>num_samples</code> times, depending on its complexity.
</p>

<div align="middle">
	<table style="width: 100%">
	  <tr align="center">
		<td>
		  <img src="https://media.discordapp.net/attachments/1206890319845523516/1217226928696594552/bunny.png?ex=660341ea&is=65f0ccea&hm=6303054d7c451ab3d6e20fb4882a9477f2bb4175c9e1e6f0f6468275184c1f52&=&format=webp&quality=lossless&width=600&height=450" align="middle" width="400px"/>
		  <figcaption align="middle">CBbunny.dae</figcaption>
		</td>
		<td>
			<img src="https://media.discordapp.net/attachments/1206890319845523516/1217226954051289159/bunny_rate.png?ex=660341f0&is=65f0ccf0&hm=f8da6aa0c3f1ca89ea031ebe36efca19157be9c7f213dd0e4427f5a7636f2ef4&=&format=webp&quality=lossless&width=600&height=450" align="middle" width="400px"/>
			<figcaption align="middle">Sample rate image for CBbunny.dae</figcaption>
		</td>
	  </tr>
	</table>
</div>
<div align="middle">
	<table style="width: 100%">
	  <tr align="center">
		<td>
		  <img src="https://media.discordapp.net/attachments/1206890319845523516/1217227669024800768/bunny.png?ex=6603429b&is=65f0cd9b&hm=8294c8a3950866e2cce48fc66c597f82baf93ea120884fd63c15b29dd2296d00&=&format=webp&quality=lossless&width=600&height=450" align="middle" width="400px"/>
		  <figcaption align="middle">CBspheres_lambertian.dae</figcaption>
		</td>
		<td>
			<img src="https://media.discordapp.net/attachments/1206890319845523516/1217227727346733168/bunny_rate.png?ex=660342a9&is=65f0cda9&hm=342cca88b830ade85f351637bf9b16558902d09832777f8285b76e7b7f348757&=&format=webp&quality=lossless&width=600&height=450" align="middle" width="400px"/>
			<figcaption align="middle">Sample rate image for CBspheres_lambertian</figcaption>
		</td>
	  </tr>
	</table>
</div>

</body>
</html>